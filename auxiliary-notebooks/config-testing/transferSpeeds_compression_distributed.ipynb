{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transfer Speeds - Compression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports & Client Initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import dask.array as dsa\n",
    "import numpy as np\n",
    "import dask.dataframe as dd\n",
    "from contextlib import contextmanager\n",
    "import xarray as xr\n",
    "import intake\n",
    "import time\n",
    "import dask\n",
    "from matplotlib import pyplot as plt\n",
    "from matplotlib.pyplot import cm\n",
    "from matplotlib.ticker import MaxNLocator\n",
    "import matplotlib.colors\n",
    "import pandas as pd\n",
    "from scipy.stats import sem\n",
    "import tiledb\n",
    "import socket\n",
    "print(socket.gethostname())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dask.distributed import Client\n",
    "from dask_jobqueue import SLURMCluster\n",
    "\n",
    "dask_dir = '/mnt/shared/dask'\n",
    "conda_dir = '/var/lib/pworks/miniconda3'\n",
    "conda_env = 'cloud-data'\n",
    "print('Conda Directory:', conda_dir, '\\nConda Environment:', conda_env)\n",
    "\n",
    "cluster = SLURMCluster(project='ca-cloudmgmt',\n",
    "                       cores=4, # Number of cores in the job\n",
    "                       memory='16GB', # Worker memory limit will be memory/processes\n",
    "                       processes=4, # Sets number of Dask workers. Threads per dask worker will be cores/processes\n",
    "                       name='gcpv2slurmbasic', # Name of cluster\n",
    "                       queue='compute', # Partition name\n",
    "                       job_cpu=4, # Set this to the number of cpus per job\n",
    "                       job_mem='16GB', # Amount of memory per job\n",
    "                       walltime='01:00:00',\n",
    "                       log_directory=os.path.join(dask_dir, 'logs'),\n",
    "                       env_extra=[\n",
    "                           'source {conda_sh}; conda activate {conda_env}'.format(\n",
    "                           conda_sh = os.path.join(conda_dir, 'etc/profile.d/conda.sh'),\n",
    "                           conda_env= conda_env\n",
    "                           )\n",
    "                       ],\n",
    "                       header_skip=['--mem'],\n",
    "                      )\n",
    "\n",
    "client = Client(cluster)\n",
    "print('Job Script:\\n',cluster.job_script())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Benchmarking Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DevNullStore:\n",
    "    def __init__(self):\n",
    "        pass\n",
    "    def __setitem__(*args, **kwargs):\n",
    "        pass\n",
    "\n",
    "null_store = DevNullStore()\n",
    "\n",
    "class DiagnosticTimer:\n",
    "    def __init__(self):\n",
    "        self.diagnostics = []\n",
    "        self.names = []\n",
    "        \n",
    "    @contextmanager\n",
    "    def time(self, **kwargs):\n",
    "        tic = time.time()\n",
    "        yield\n",
    "        toc = time.time()\n",
    "        kwargs[\"runtime\"] = toc - tic\n",
    "        self.diagnostics.append(kwargs)\n",
    "        \n",
    "    def dataframe(self):\n",
    "        return pd.DataFrame(self.diagnostics)\n",
    "    \n",
    "diag_timer = DiagnosticTimer()\n",
    "\n",
    "def name(fileType, daf): \n",
    "    globals()[f\"df_{fileType}\"] = daf\n",
    "    diag_timer.names.append(globals()[f\"df_{fileType}\"])\n",
    "    \n",
    "    global df, da\n",
    "    del df, da\n",
    "    diag_timer.diagnostics = []\n",
    "\n",
    "def total_nthreads():\n",
    "    return sum([v for v in client.nthreads().values()])\n",
    "\n",
    "def total_ncores():\n",
    "    return sum([v for v in client.ncores().values()])\n",
    "\n",
    "def total_workers():\n",
    "    return len(client.ncores())\n",
    "\n",
    "class mainLoop:\n",
    "    def errorCalc(self, df0):\n",
    "        global tests\n",
    "        newVals = []\n",
    "        info = []\n",
    "        thrPut = df0['throughput_Mbps']\n",
    "        rTime = df0['runtime']\n",
    "        for i in np.linspace(0, len(thrPut)-tests, int(len(thrPut)/tests), dtype='int'):\n",
    "            means = thrPut[slice(i,(i+tests))].mean()\n",
    "            runtime = rTime[slice(i,(i+tests))].mean()\n",
    "            errors = sem(thrPut[slice(i,(i+tests))])\n",
    "            error_kwargs = dict(runtime = runtime, throughput_Mbps = means, errors = errors)\n",
    "            info.append(df0.iloc[i, 0:7])\n",
    "            newVals.append(error_kwargs)\n",
    "        \n",
    "        df1 = pd.DataFrame(info, index=range(len(info)))\n",
    "        df2 = pd.DataFrame(newVals)\n",
    "        df = pd.concat([df1, df2], axis=1)\n",
    "        return df\n",
    "\n",
    "    def loop(self, da, diag_kwargs):\n",
    "        global tests, max_workers, worker_step\n",
    "        worker_range = np.arange(max_workers, 0, -worker_step)\n",
    "        worker_range = np.insert(worker_range,0, max_workers)\n",
    "        for nworkers in worker_range:\n",
    "            cluster.scale(nworkers)\n",
    "            time.sleep(10)\n",
    "            client.wait_for_workers(nworkers)\n",
    "            print('Number of Workers:', nworkers)\n",
    "            for i in range(tests):\n",
    "                with diag_timer.time(nworkers=total_workers(), nthreads=total_nthreads(), ncores=total_ncores(),\n",
    "                                     **diag_kwargs):\n",
    "                    future = dsa.store(da, null_store, lock=False, compute=False)\n",
    "                    dask.compute(future, retries=5)\n",
    "                del future\n",
    "        \n",
    "        df = diag_timer.dataframe()\n",
    "        df['throughput_Mbps'] = da.nbytes / 1e6 / df['runtime']\n",
    "        if i != 0:\n",
    "            df = self.errorCalc(df)\n",
    "        #df.drop(index=df.index[0], \n",
    "        #axis=0, \n",
    "        #inplace=True)\n",
    "        #df.reset_index(drop=True, inplace=True)\n",
    "        return df\n",
    "\n",
    "mainLoop = mainLoop()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Perform Benchmarking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loop Parameters\n",
    "tests = 5\n",
    "max_workers = 40\n",
    "worker_step = 4\n",
    "\n",
    "# Data Location\n",
    "root = 'gs://cloud-data-benchmarks/'\n",
    "data = 'ETOPO1_Ice_g_gmt4'\n",
    "token = '/var/lib/pworks/cloud-data-benchmarks.json'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tabular Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Parquet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "compressors = ['.100MB', '.lz4', '.gzip', '.zstd'] # '.100MB' = 'snappy'\n",
    "\n",
    "for i in compressors:\n",
    "    print('Compression Algorithm:',i.split('.')[-1])\n",
    "    cluster.scale(max_workers)\n",
    "    client.wait_for_workers(max_workers)\n",
    "    tic1 = time.time()\n",
    "    df0 = dd.read_parquet(root + data + i + '.partparquet/*', storage_options={'token':token})\n",
    "    toc1 = time.time()\n",
    "    connectTime = toc1 - tic1\n",
    "\n",
    "    da = df0.to_dask_array(lengths=True)\n",
    "    del df0\n",
    "    chunksize = np.prod(da.chunksize) * da.dtype.itemsize\n",
    "    cluster.scale(0)\n",
    "    if i == '.100MB':\n",
    "        diag_kwargs = dict(nbytes=da.nbytes, chunksize=chunksize, format='parquet',\n",
    "                           compressor='snappy', connectTime=connectTime)\n",
    "    else:\n",
    "        diag_kwargs = dict(nbytes=da.nbytes, chunksize=chunksize, format='parquet',\n",
    "                           compressor=i.split('.')[-1], connectTime=connectTime)\n",
    "\n",
    "    df = mainLoop.loop(da, diag_kwargs)\n",
    "    name('partparquet', df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gridded Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "intake.open_netcdf(root + data + '.100MB.nc',\n",
    "                   storage_options={'token':token}).to_dask().data_vars # Lists all data variables contained in the data set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "variable = 'SLP'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Zarr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "compressors = ['.blosclz', '.100MB', '.lz4hc', '.zlib', '.zstd', '.gzip', '.bzip2'] # '.100MB' = 'lz4'\n",
    "\n",
    "for i in compressors:\n",
    "    print('Compression Algorithm:',i.split('.')[-1])\n",
    "    tic1 = time.time()\n",
    "    ds = xr.open_zarr(store = root + data + i + '.zarr', consolidated=True,\n",
    "                   storage_options={'token':token})\n",
    "    toc1 = time.time()\n",
    "    connectTime = toc1-tic1\n",
    "    da = ds[variable].data\n",
    "    del ds\n",
    "    chunksize = np.prod(da.chunksize) * da.dtype.itemsize\n",
    "    if i == '.100MB':\n",
    "        diag_kwargs = dict(nbytes=da.nbytes, chunksize=chunksize, format='Zarr', compressor='lz4', connectTime=connectTime)\n",
    "    else:\n",
    "        diag_kwargs = dict(nbytes=da.nbytes, chunksize=chunksize, format='Zarr',\n",
    "                           compressor=i.split('.')[-1], connectTime=connectTime)\n",
    "\n",
    "    df = mainLoop.loop(da, diag_kwargs)\n",
    "    name('zgroup', df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### TileDB Embedded "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "compressors = []\n",
    "os.environ('GOOGLE_APPLICATION_CREDENTIALS')=token\n",
    "\n",
    "for i in compressors:\n",
    "    print('Compression Algorithm',i.split('.')[-1])\n",
    "    tic1 = time.time()\n",
    "    da = dsa.from_tiledb(root + data + '.tldb')\n",
    "    toc1 = time.time()\n",
    "    connectTime = toc1 - tic1\n",
    "    chunksize = np.prod(da.chunksize) * da.dtype.itemsize\n",
    "    if i == '.100MB':\n",
    "        diag_kwargs = dict(nbytes=da.nbytes, chunksize=chunksize, format='tiledb',\n",
    "                           compressor='LZ4', connectTime=connectTime)\n",
    "    else:\n",
    "        diag_kwargs = dict(nbytes=da.nbytes, chunksize=chunksize, format='tiledb',\n",
    "                           compressor=i.split('.')[-1], connectTime=connectTime)\n",
    "\n",
    "    df = mainLoop.loop(da, diag_kwargs)\n",
    "    name('tldb', df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-------------------------------------------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster.scale(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "client.close()\n",
    "cluster.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot Throughput"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_results = pd.concat(diag_timer.names, ignore_index=True)\n",
    "pd.set_option('display.max_rows', None)\n",
    "df_results"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "SSH gcpslurmv2basic.clusters.pw gcpslurmv2basic-cloud-data",
   "language": "",
   "name": "rik_ssh_gcpslurmv2basic_clusters_pw_gcpslurmv2basicclouddata"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
